{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:44:25.629605Z",
     "iopub.status.busy": "2025-12-23T21:44:25.629426Z",
     "iopub.status.idle": "2025-12-23T21:44:26.059950Z",
     "shell.execute_reply": "2025-12-23T21:44:26.059650Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "# import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:44:26.061669Z",
     "iopub.status.busy": "2025-12-23T21:44:26.061541Z",
     "iopub.status.idle": "2025-12-23T21:44:26.065623Z",
     "shell.execute_reply": "2025-12-23T21:44:26.065218Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "API_BASE = \"https://gamma-api.polymarket.com\"\n",
    "\n",
    "def fetch_events(limit=100, offset=0, min_volume=1000000):\n",
    "    url = (\n",
    "        f\"{API_BASE}/events?\"\n",
    "        f\"limit={limit}&offset={offset}&volume_min={min_volume}&active=true&closed=false\"\n",
    "    )\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def fetch_all_events(min_volume=1000000):\n",
    "    all_events = []\n",
    "    offset = 0\n",
    "    limit = 100\n",
    "\n",
    "    while offset < 600:\n",
    "        print(f\"Fetching offset={offset} ...\")\n",
    "\n",
    "        data = fetch_events(limit=limit, offset=offset, min_volume=min_volume)\n",
    "\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        all_events.extend(data)\n",
    "        offset += limit\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    return all_events\n",
    "\n",
    "\n",
    "def flatten_events(events):\n",
    "    event_fields = [\n",
    "        \"id\", \"slug\", \"title\", \"creationDate\", \"endDate\", \"startDate\", \"volume\"\n",
    "    ]\n",
    "\n",
    "    market_fields = [\n",
    "        \"id\", \"slug\", \"question\", \"startDate\", \"endDate\", \"volume\", \n",
    "        \"outcomes\", \"outcomePrices\", \"active\", \"closed\", \"bestBid\", \"bestAsk\"\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for event in events:\n",
    "        event_data = {f\"event_{k}\": event.get(k) for k in event_fields}\n",
    "\n",
    "        # --- event-level tags ---\n",
    "        event_tags = [\n",
    "            t.get(\"slug\")\n",
    "            for t in event.get(\"tags\", [])\n",
    "            if isinstance(t, dict) and t.get(\"slug\")\n",
    "        ]\n",
    "\n",
    "        for market in event.get(\"markets\", []):\n",
    "            market_data = {f\"market_{k}\": market.get(k) for k in market_fields}\n",
    "\n",
    "            # --- market-level tags ---\n",
    "            market_tags = [\n",
    "                t.get(\"slug\")\n",
    "                for t in market.get(\"tags\", [])\n",
    "                if isinstance(t, dict) and t.get(\"slug\")\n",
    "            ]\n",
    "\n",
    "            # merge & deduplicate tags\n",
    "            all_tags = sorted(set(event_tags + market_tags))\n",
    "            \n",
    "\n",
    "            row = {\n",
    "                \"market_id\": market.get(\"id\"),\n",
    "                \"tags\": \",\".join(all_tags),\n",
    "                **event_data,\n",
    "                **market_data\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['created_at'] = datetime.now(timezone.utc).replace(microsecond=0).isoformat(timespec='seconds').replace('+00:00', '')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:44:26.067230Z",
     "iopub.status.busy": "2025-12-23T21:44:26.067131Z",
     "iopub.status.idle": "2025-12-23T21:44:26.069501Z",
     "shell.execute_reply": "2025-12-23T21:44:26.069252Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Fetching Polymarket events...\")\n",
    "    events = fetch_all_events()\n",
    "    print(f\"Fetched {len(events)} events.\")\n",
    "\n",
    "    # Flatten markets\n",
    "    df = flatten_events(events)\n",
    "\n",
    "    old_file = Path(\"data/polymarket_flat_markets_t0.csv\")\n",
    "    new_file = Path(\"data/polymarket_flat_markets_t1.csv\")\n",
    "\n",
    "    try:\n",
    "        # Rename old t1 to t0 (overwrite if exists)\n",
    "        if new_file.exists():\n",
    "            new_file.replace(old_file)  # replace() overwrites t0 if it exists\n",
    "            print(f\"Renamed {new_file.name} to {old_file.name}\")\n",
    "\n",
    "        # Save the new CSV as t1\n",
    "        df.to_csv(new_file, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {new_file.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}. Saving backup...\")\n",
    "        backup_file = Path(\"data/polymarket_flat_markets_backup.csv\")\n",
    "        df.to_csv(backup_file, index=False)\n",
    "        print(f\"Saved backup to {backup_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:44:26.070672Z",
     "iopub.status.busy": "2025-12-23T21:44:26.070600Z",
     "iopub.status.idle": "2025-12-23T21:44:40.083356Z",
     "shell.execute_reply": "2025-12-23T21:44:40.083044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Polymarket events...\n",
      "Fetching offset=0 ...\n",
      "Fetching offset=100 ...\n",
      "Fetching offset=200 ...\n",
      "Fetching offset=300 ...\n",
      "Fetched 208 events.\n",
      "Renamed polymarket_flat_markets_t1.csv to polymarket_flat_markets_t0.csv\n",
      "Saved 3452 rows to polymarket_flat_markets_t1.csv\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
